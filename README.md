# ğŸŸ¡ Simpsons Character Classifier

A deep learning project to classify Simpsons characters from images.

It consists of:

* ğŸ¨ **Frontend (Streamlit):** [simpsons-predict.streamlit.app](https://simpsons-predict.streamlit.app/)
* âš¡ **Backend (FastAPI):** [binnyman-simp.hf.space](https://binnyman-simp.hf.space)
* ğŸ§  **Model Training:** OpenCV + Caer + Canaro (Keras/TensorFlow)

---
## ğŸ—‚ï¸ Project Structure

```text
Titanic_ship/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py             # FastAPI app (API endpoints)
â”‚   â”œâ”€â”€ requirements.txt    # Dependencies for backend
â”‚   â”œâ”€â”€ start.sh            # Startup script
|   â”œâ”€â”€ simpsons_model.h5   
â”‚   â”œâ”€â”€ labels.pkl   
â”‚   â””â”€â”€ train.py            # Model training script
â”œâ”€â”€ frontend/
    â”œâ”€â”€ index.py            # Streamlit app
    â””â”€â”€ requirements.txt    # Dependencies for frontend

```

<h3>ğŸ“Š Screenshots</h3>
<p align="center"> <img src="./screenshots/backend.png" alt="FastAPI Docs" width="45%" /> <img src="./screenshots/frontend1.png" alt="Streamlit UI" width="45%" /> </p>
## ğŸš€ How it Works

1. A **Convolutional Neural Network** is trained on the Simpsons dataset.
2. The model is saved as `simpsons_model.h5` with labels stored in `labels.pkl`.
3. The **FastAPI backend** loads the model and exposes an API endpoint `/classify`.
4. The **Streamlit frontend** lets users upload an image â†’ forwards it to the backend â†’ displays the predicted character.

---

## ğŸ›  Tech Stack

* **Data Processing:** OpenCV, Caer
* **Modeling:** Canaro, TensorFlow / Keras
* **Backend:** FastAPI, Uvicorn
* **Frontend:** Streamlit
* **Other:** NumPy, Joblib, Matplotlib

---

## ğŸ§‘â€ğŸ« Model Training

The dataset used was the **Simpsons Character Dataset** (organized into subfolders per character).

### Key steps:

* Preprocessed images with **OpenCV** (`cv2`) and resized to `80x80`.
* Converted dataset to grayscale (`channels=1`).
* Selected **top 100 characters** with most samples.
* Used `caer` and `canaro` to handle preprocessing, augmentation, and model creation.
* Normalized data and split into training/validation sets.
* Trained a CNN model for **10 epochs** with a batch size of 32.
* Saved the trained model and labels:

  ```python
  model.save("simpsons_model.h5")
  joblib.dump(character, "labels.pkl")
  ```

### Sample Training Code

```python
model = canaro.models.createSimpsonsModel(
    IMG_SIZE=(80, 80),
    channels=1,
    output_dim=len(character),
    loss='categorical_crossentropy',
    learning_rate=0.001,
    momentum=0.9,
    nesterov=True
)

training = model.fit(
    train_gen,
    steps_per_epoch=len(xtrain)//BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(xtest, ytest),
    callbacks=[LearningRateScheduler(canaro.lr_schedule)]
)
```

---

## ğŸ“¡ API Usage (Backend)

**Endpoint:**

```
POST https://binnyman-simp.hf.space/classify
```

**Parameters:**

* `file` â†’ image file (`jpg`, `jpeg`, `png`)

**Example with `curl`:**

```bash
curl -X POST "https://binnyman-simp.hf.space/classify" \
  -F "file=@your_image.jpg"
```

**Response:**

```json
{
  "predicted_label": "Homer Simpson"
}
```

---

## â–¶ï¸ Local Development

### 1. Clone the repo

```bash
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>
```

### 2. Backend (FastAPI)

```bash
pip install -r requirements.txt
uvicorn app:app --reload --host 0.0.0.0 --port 7860
```

### 3. Frontend (Streamlit)

```bash
streamlit run frontend.py
```

### 4. Training (Optional)

If you want to retrain the model:

```bash
python train.py
```

---

## ğŸ“· Demo

* Upload an image of a Simpsons character.
* Get instant predictions from the trained model.

ğŸ‘‰ Try the apps:

* [Frontend App](https://simpsons-predict.streamlit.app/)
* [Backend API](https://binnyman-simp.hf.space)

---

## ğŸ“œ License

This project is open-source. Contributions are welcome!
